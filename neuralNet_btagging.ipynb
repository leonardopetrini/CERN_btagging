{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeuralNets for b-tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from bob import *\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFileName = 'Hybrid_25_July_bugfixed_fullStat.pkl'\n",
    "\n",
    "# Subsample the dataset for fast execution\n",
    "subsampleFlag = True\n",
    "gpuFlag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = pd.read_pickle(inputFileName)\n",
    "features = select_features(tree, to_remove=[])\n",
    "\n",
    "# Add flag for missing values in SV1\n",
    "tree['nan_flag'] = tree['jet_sv1_sig3d'] == -100\n",
    "features.append('nan_flag')\n",
    "\n",
    "if subsampleFlag:\n",
    "    tree = tree.head(int(tree.shape[0]*0.05))\n",
    "    num_boost_round=100\n",
    "else:\n",
    "    num_boost_round=1000\n",
    "    \n",
    "# Replace missing values with NaNs\n",
    "d = dict.fromkeys([-100, -1, -99, -1000], np.nan)\n",
    "tree.replace(d, inplace=True)\n",
    "\n",
    "# Normalization\n",
    "tree[features] = tree[features].apply(lambda x: (x-x.mean())/x.std(), axis=0)\n",
    "\n",
    "tree.replace(np.nan, 0, inplace=True)\n",
    "\n",
    "tree['jet_LabDr_HadF'].replace(to_replace=5, value=2, inplace=True) \n",
    "tree['jet_LabDr_HadF'].replace(to_replace=4, value=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_splitting(tree)\n",
    "train = train.head(train.shape[0]//10000*10000)\n",
    "test = test.head(400000)\n",
    "train['weights'] = train['weights'] / train['weights'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_target = Variable(torch.from_numpy(train[features].values.astype(np.float32))), \\\n",
    "                            Variable(torch.from_numpy((train['jet_LabDr_HadF'].values).astype(np.int))).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leope\\Anaconda3\\envs\\pyth\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test_input, test_target = Variable(torch.from_numpy(test[features].values.astype(np.float32)), volatile=True), \\\n",
    "                            Variable(torch.from_numpy((test['jet_LabDr_HadF'].values).astype(np.int)), volatile=True).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gpuFlag:\n",
    "    train_input, train_target, test_input, test_target = train_input.cuda(), train_target.cuda(), test_input.cuda(), test_target.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(25, 100)\n",
    "        self.fc1_bn = nn.BatchNorm1d(100)\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.fc2_bn = nn.BatchNorm1d(100)\n",
    "        self.fc3 = nn.Linear(100, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1_bn(F.relu(self.fc1(x)))\n",
    "        x = self.fc2_bn(F.relu(self.fc2(x)))\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "model, criterion = Net(), nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using the function nn.sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [nn.Linear(25, 128),\n",
    "          nn.ReLU(),\n",
    "          nn.Dropout(0.75),\n",
    "         nn.BatchNorm1d(128),\n",
    "         nn.Linear(128, 64),\n",
    "          nn.ReLU(),\n",
    "          nn.Dropout(0.75),\n",
    "         nn.BatchNorm1d(64),\n",
    "         nn.Linear(64, 32),\n",
    "          nn.ReLU(),\n",
    "          nn.Dropout(0.75),\n",
    "         nn.BatchNorm1d(32),\n",
    "         nn.Linear(32, 3)]\n",
    "#model = nn.Sequential(*layers)\n",
    "#criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████                                                                    | 12/80 [11:43<1:06:28, 58.65s/it]"
     ]
    }
   ],
   "source": [
    "if gpuFlag:\n",
    "    model.cuda()\n",
    "\n",
    "learning_rate = .001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)\n",
    "\n",
    "mini_batch_size = 10000\n",
    "generalization_loss = []\n",
    "\n",
    "for e in tqdm(range(80)):\n",
    "    sum_loss = 0\n",
    "    model.train()\n",
    "    # We do this with mini-batches\n",
    "    for batch in range(240):\n",
    "    #Choose indices of minibatch considering weights\n",
    "        idxs = np.random.choice(train_input.shape[0], size=mini_batch_size, p=train['weights'].values)\n",
    "        output = model(train_input[idxs])\n",
    "        loss = criterion(output, train_target[idxs])\n",
    "        sum_loss = sum_loss + loss.item()\n",
    "        optimizer.zero_grad()        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.eval()\n",
    "    output = model(test_input.narrow(0, 0, mini_batch_size))\n",
    "    loss = criterion(output, test_target.narrow(0, 0, mini_batch_size))\n",
    "    generalization_loss.append(loss.item())\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "print(e, sum_loss)\n",
    "plt.plot(generalization_loss);\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), 'mymodel.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load('mymodel.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = F.softmax(model(test_input.narrow(0, 0, 400000)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gpuFlag:\n",
    "    test_pred = test_pred.cpu()\n",
    "test_pred = test_pred.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['jet_LabDr_HadF'].replace(to_replace=2, value=5, inplace=True) \n",
    "test['jet_LabDr_HadF'].replace(to_replace=1, value=4, inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define discriminant with 3 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 0.1\n",
    "ll = np.log(test_pred.T[2]/(f*test_pred.T[1] + (1-f)*test_pred.T[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_c_dnn, tpr_c_dnn = compute_roc(test['jet_LabDr_HadF'].values, ll, 'c')\n",
    "fpr_l_dnn, tpr_l_dnn = compute_roc(test['jet_LabDr_HadF'].values, ll, 'l')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_c_mv, tpr_c_mv = compute_roc(test['jet_LabDr_HadF'].values, test['jet_mv2c10'].values, 'c')\n",
    "fpr_l_mv, tpr_l_mv = compute_roc(test['jet_LabDr_HadF'].values, test['jet_mv2c10'].values, 'l')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_light = 1 /fpr_l_dnn[1:] / interpolate.spline(tpr_l_mv[1:], 1/fpr_l_mv[1:], tpr_l_dnn[1:], order=1)\n",
    "rate_c = 1 /fpr_c_dnn[1:] / interpolate.spline(tpr_c_mv[1:], 1/fpr_c_mv[1:], tpr_c_dnn[1:], order=1)\n",
    "\n",
    "rate_light[rate_light==np.inf] = np.nan\n",
    "rate_c[rate_c==np.inf] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10,7))\n",
    "\n",
    "gs=GridSpec(5,1)\n",
    "\n",
    "ax1=fig.add_subplot(gs[0:4,0])\n",
    "ax2=fig.add_subplot(gs[4,0])\n",
    "\n",
    "ax1.set_ylabel(\"light / c rejection\")\n",
    "ax1.semilogy(tpr_l_mv, 1/fpr_l_mv, label='light MV2', c='orangered')\n",
    "ax1.semilogy(tpr_c_mv, 1/fpr_c_mv, label='c MV2', c='dodgerblue')\n",
    "\n",
    "ax1.semilogy(tpr_l_dnn, 1/fpr_l_dnn, label='light dnn', c='brown')\n",
    "ax1.semilogy(tpr_c_dnn, 1/fpr_c_dnn, label='c dnn', c='navy')\n",
    "\n",
    "plt.setp(ax1.get_xticklabels(), visible=False)\n",
    "ax1.set_xlim([0.55, 1])\n",
    "ax1.set_ylim([1, 1e3])\n",
    "\n",
    "ax1.grid()\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(tpr_l_dnn[1:], 1/rate_light, c='r', lw=.8,  label='l-jets')\n",
    "\n",
    "ax2.plot(tpr_c_dnn[1:], 1/rate_c, c='b', lw=.8,  label='c-jets')\n",
    "\n",
    "ax2.axhline(y=1, color='black', linestyle='-.', lw=.5)\n",
    "ax2.grid()\n",
    "ax2.set_xlabel(\"b-efficiency\")\n",
    "ax2.set_ylabel(\"rate\")\n",
    "ax2.set_xlim([0.55, 1])\n",
    "ax2.set_ylim([0.5, 1.5])\n",
    "ax2.legend(fontsize = 'x-small')\n",
    "\n",
    "plt.savefig('figures/dnn_mv2_efficiency_vs_rejection.eps', format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rejection_pt(test, test['jet_mv2c10'].values, ll, num_cuts=15)\n",
    "plt.savefig('figures/dnn_mv2_rejection_vs_pt.eps', format='eps')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
