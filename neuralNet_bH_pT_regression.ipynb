{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeuralNets for b-hadron pT regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from bob import *\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFileName = 'MC16d_newTrain_Zprime.pkl'\n",
    "\n",
    "# Subsample the dataset for fast execution\n",
    "subsampleFlag = False\n",
    "gpuFlag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = pd.read_pickle(inputFileName)\n",
    "features = select_features(tree, to_remove=[])\n",
    "\n",
    "# Add flag for missing values in SV1\n",
    "tree['nan_flag'] = tree['jet_sv1_sig3d'] == -100\n",
    "features.append('nan_flag')\n",
    "\n",
    "tree['jet_bH_pt'] = tree['jet_bH_pt'].apply(lambda x: x[0])\n",
    "\n",
    "if subsampleFlag:\n",
    "    tree = tree.head(int(tree.shape[0]*0.05))\n",
    "    num_boost_round=100\n",
    "else:\n",
    "    num_boost_round=1000\n",
    "    \n",
    "# Replace missing values with NaNs\n",
    "d = dict.fromkeys([-100, -1, -99, -1000], np.nan)\n",
    "tree.replace(d, inplace=True)\n",
    "\n",
    "# Normalization\n",
    "tree[features] = tree[features].apply(lambda x: (x-x.mean())/x.std(), axis=0)\n",
    "\n",
    "tree.replace(np.nan, 0, inplace=True)\n",
    "\n",
    "tree['jet_LabDr_HadF'].replace(to_replace=5, value=2, inplace=True) \n",
    "tree['jet_LabDr_HadF'].replace(to_replace=4, value=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bh_pt_std = tree['jet_bH_pt'].std()\n",
    "pt_mean = tree['jet_pt'].mean()\n",
    "pt_std = tree['jet_pt'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree['jet_bH_pt'] = tree['jet_bH_pt'] / bh_pt_std\n",
    "tree['jet_pt'] = (tree['jet_pt'] - pt_mean) / pt_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_splitting(tree)\n",
    "train = train.head(train.shape[0]//100*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_target = Variable(torch.from_numpy(train[features].values.astype(np.float32))), \\\n",
    "                            Variable(torch.from_numpy((train['jet_bH_pt'].values.astype(np.float32))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input, test_target = Variable(torch.from_numpy(test[features].values.astype(np.float32)), volatile=True), \\\n",
    "                            Variable(torch.from_numpy((test['jet_bH_pt'].values.astype(np.float32))), volatile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gpuFlag:\n",
    "    train_input, train_target, test_input, test_target = train_input.cuda(), train_target.cuda(), test_input.cuda(), test_target.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(25, 100)\n",
    "        self.fc1_bn = nn.BatchNorm1d(100)\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.fc2_bn = nn.BatchNorm1d(100)\n",
    "        self.fc3 = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1_bn(F.relu(self.fc1(x)))\n",
    "        x = self.fc2_bn(F.relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        x = torch.mul(x,x).flatten()\n",
    "        return x\n",
    "    \n",
    "model, criterion = Net(), nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gpuFlag:\n",
    "    model.cuda()\n",
    "\n",
    "learning_rate = .001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)\n",
    "\n",
    "mini_batch_size = 100\n",
    "generalization_loss = []\n",
    "\n",
    "for e in tqdm(range(30)):\n",
    "    sum_loss = 0\n",
    "    model.train()\n",
    "    idxs = np.random.permutation(train_input.size(0))\n",
    "    # We do this with mini-batches\n",
    "    for b in range(0, train_input.size(0), mini_batch_size):\n",
    "        output = model(train_input[idxs].narrow(0, b, mini_batch_size))\n",
    "        loss = criterion(output, train_target[idxs].narrow(0, b, mini_batch_size))\n",
    "        sum_loss = sum_loss + loss.item()\n",
    "        optimizer.zero_grad()        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    output = model(test_input)\n",
    "    loss = criterion(output, test_target)\n",
    "    if loss.item() < 1e3:\n",
    "        generalization_loss.append(loss.item())\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "print(e, sum_loss)\n",
    "plt.plot(generalization_loss);\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), 'mymodel.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load('mymodel.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gpuFlag:\n",
    "    output = output.cpu()\n",
    "pt_pred = output.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_pred = pt_pred * pt_std\n",
    "test['jet_bH_pt'] = test['jet_bH_pt'] * bh_pt_std\n",
    "test['jet_pt'] = (test['jet_pt'] * pt_std) + pt_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5.5))\n",
    "plt.hist((pt_pred[test['jet_LabDr_HadF']==5],pt_pred[test['jet_LabDr_HadF']==4],pt_pred[test['jet_LabDr_HadF']==0], \\\n",
    "         test['jet_pt'][test['jet_LabDr_HadF']==5],test['jet_pt'][test['jet_LabDr_HadF']==4],pt_pred[test['jet_LabDr_HadF']==0]),\\\n",
    "         log=True, density=True, label=('b','c','l'), bins=120, histtype = 'step');\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "#plt.xlim([0,1.7e6])\n",
    "plt.xlabel('$p_T$ predicted (regression) [TeV]')\n",
    "plt.ylabel('prob. density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,1.4,50)\n",
    "\n",
    "plt.figure(1,) #figsize=(10,6))\n",
    "degrees = [1]       # list of degrees of x to use\n",
    "matrix = np.stack([test['jet_bH_pt']**d for d in degrees], axis=-1)   # stack them like columns\n",
    "#slope, r, _, _ = np.linalg.lstsq(matrix, pt_pred)\n",
    "slope = 1\n",
    "plt.plot(x, x*slope, 'r')\n",
    "print(slope, 1-sum((test['jet_bH_pt'] - pt_pred)**2)/sum((pt_pred - pt_pred.mean())**2) )\n",
    "\n",
    "h = np.histogram2d(test['jet_bH_pt'], pt_pred, bins=(np.linspace(0,1.4e6,112),np.linspace(0,1.4e6,112)), density=True)\n",
    "plt.imshow(h[0].T, norm=matplotlib.colors.LogNorm(), extent=[0,1.4,0,1.4], origin='lower')\n",
    "plt.xlabel('jet_bH_pt [TeV]')\n",
    "plt.ylabel('regression_pt [TeV]')\n",
    "plt.colorbar()\n",
    "plt.grid()\n",
    "\n",
    "plt.figure(2,) #figsize=(10,6))\n",
    "\n",
    "slope, r, _, _ = np.linalg.lstsq(matrix, test['jet_pt'])\n",
    "plt.plot(x, x*slope, 'r')\n",
    "print(slope, 1-r/sum((test['jet_pt'] - test['jet_pt'].mean())**2) )\n",
    "\n",
    "h = np.histogram2d(test['jet_bH_pt'], test['jet_pt'], bins=(np.linspace(0,1.4e6,112),np.linspace(0,1.4e6,112)), density=True)\n",
    "plt.imshow(h[0].T, norm=matplotlib.colors.LogNorm(), extent=[0,1.4,0,1.4], origin='lower')\n",
    "plt.xlabel('jet_bH_pt [TeV]')\n",
    "plt.ylabel('jet_pt [TeV]')\n",
    "plt.colorbar()\n",
    "plt.grid()\n",
    "plt.savefig('jetbHpt_jetpt.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
